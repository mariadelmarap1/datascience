{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80db86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aa4489f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0       1    13.20        1.78  2.14               11.2        100   \n",
      "1       1    13.16        2.36  2.67               18.6        101   \n",
      "2       1    14.37        1.95  2.50               16.8        113   \n",
      "3       1    13.24        2.59  2.87               21.0        118   \n",
      "4       1    14.20        1.76  2.45               15.2        112   \n",
      "5       1    14.39        1.87  2.45               14.6         96   \n",
      "6       1    14.06        2.15  2.61               17.6        121   \n",
      "7       1    14.83        1.64  2.17               14.0         97   \n",
      "8       1    13.86        1.35  2.27               16.0         98   \n",
      "9       1    14.10        2.16  2.30               18.0        105   \n",
      "10      1    14.12        1.48  2.32               16.8         95   \n",
      "11      1    13.75        1.73  2.41               16.0         89   \n",
      "12      1    14.75        1.73  2.39               11.4         91   \n",
      "13      1    14.38        1.87  2.38               12.0        102   \n",
      "14      1    13.63        1.81  2.70               17.2        112   \n",
      "15      1    14.30        1.92  2.72               20.0        120   \n",
      "16      1    13.83        1.57  2.62               20.0        115   \n",
      "17      1    14.19        1.59  2.48               16.5        108   \n",
      "18      1    13.64        3.10  2.56               15.2        116   \n",
      "19      1    14.06        1.63  2.28               16.0        126   \n",
      "\n",
      "    Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0            2.65        2.76                  0.26             1.28   \n",
      "1            2.80        3.24                  0.30             2.81   \n",
      "2            3.85        3.49                  0.24             2.18   \n",
      "3            2.80        2.69                  0.39             1.82   \n",
      "4            3.27        3.39                  0.34             1.97   \n",
      "5            2.50        2.52                  0.30             1.98   \n",
      "6            2.60        2.51                  0.31             1.25   \n",
      "7            2.80        2.98                  0.29             1.98   \n",
      "8            2.98        3.15                  0.22             1.85   \n",
      "9            2.95        3.32                  0.22             2.38   \n",
      "10           2.20        2.43                  0.26             1.57   \n",
      "11           2.60        2.76                  0.29             1.81   \n",
      "12           3.10        3.69                  0.43             2.81   \n",
      "13           3.30        3.64                  0.29             2.96   \n",
      "14           2.85        2.91                  0.30             1.46   \n",
      "15           2.80        3.14                  0.33             1.97   \n",
      "16           2.95        3.40                  0.40             1.72   \n",
      "17           3.30        3.93                  0.32             1.86   \n",
      "18           2.70        3.03                  0.17             1.66   \n",
      "19           3.00        3.17                  0.24             2.10   \n",
      "\n",
      "    Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "0              4.38  1.05                          3.40     1050  \n",
      "1              5.68  1.03                          3.17     1185  \n",
      "2              7.80  0.86                          3.45     1480  \n",
      "3              4.32  1.04                          2.93      735  \n",
      "4              6.75  1.05                          2.85     1450  \n",
      "5              5.25  1.02                          3.58     1290  \n",
      "6              5.05  1.06                          3.58     1295  \n",
      "7              5.20  1.08                          2.85     1045  \n",
      "8              7.22  1.01                          3.55     1045  \n",
      "9              5.75  1.25                          3.17     1510  \n",
      "10             5.00  1.17                          2.82     1280  \n",
      "11             5.60  1.15                          2.90     1320  \n",
      "12             5.40  1.25                          2.73     1150  \n",
      "13             7.50  1.20                          3.00     1547  \n",
      "14             7.30  1.28                          2.88     1310  \n",
      "15             6.20  1.07                          2.65     1280  \n",
      "16             6.60  1.13                          2.57     1130  \n",
      "17             8.70  1.23                          2.82     1680  \n",
      "18             5.10  0.96                          3.36      845  \n",
      "19             5.65  1.09                          3.71      780  \n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "df = pd.read_csv('wineData.txt', sep=',')\n",
    "df.head()\n",
    "\n",
    "# Nombres de las columnas\n",
    "nombres_columnas = ['Class','Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "# Asignación de nuevos nombres de columnas\n",
    "df.columns = nombres_columnas\n",
    "\n",
    "#ver el archivo \n",
    "print (df[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ca1e590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo KNN: 0.94\n",
      "Matriz de confusión:\n",
      "[[19  0  0]\n",
      " [ 0 18  3]\n",
      " [ 0  0 14]]\n",
      "Precision: 0.95\n",
      "Recall: 0.94\n",
      "F1 Score: 0.94\n",
      "Sensibilidad: 1.00\n",
      "Especificidad: 1.00\n"
     ]
    }
   ],
   "source": [
    "#Exercici 1 y 2 \n",
    "#Exercici 1 Crea almenys dos models de regressió diferents per intentar predir per intentar predir el millor les classes de l'arxiu adjunt. \n",
    "#Exercici 2: Compara els models de classificació utilitzant la precisió (accuracy), una matriu de confusió i d’altres mètriques més avançades.(Precision, Recall, F1 Score, Sensibilidad, Especificidad)\n",
    "#DESARROLLO:\n",
    "#Exercici 1: primer modelo: KNN\n",
    "#Separa los datos en características (atributos) y etiquetas (clase). En este caso, la clase es la columna \"Class\" y las características son todas las demás columnas. Puedes hacerlo con las siguientes líneas de código:\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "#Separa los datos en conjuntos de entrenamiento y prueba. En este caso, utilizaremos un 70% de los datos para entrenamiento y el 30% para prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Normaliza los datos para que todas las características tengan la misma escala\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Entrena el modelo KNN utilizando el conjunto de entrenamiento. En este caso, utilizaremos un valor de k=3. \n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Haz predicciones sobre el conjunto de prueba utilizando el modelo entrenado. \n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#EXERCICI 2 Primer modelo KNN:\n",
    "#Evalúa el rendimiento del modelo calculando la precisión (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo KNN: {accuracy:.2f}')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión:')\n",
    "print(confusion)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calcular precision, recall y F1 Score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calcular sensibilidad y especificidad a partir de la matriz de confusión\n",
    "sensitivity = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "specificity = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1 Score: {:.2f}\".format(f1))\n",
    "print(\"Sensibilidad: {:.2f}\".format(sensitivity))\n",
    "print(\"Especificidad: {:.2f}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "626d947b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo KNN: 0.94\n",
      "Matriz de confusión:\n",
      "[[19  0  0]\n",
      " [ 0 18  3]\n",
      " [ 0  0 14]]\n",
      "Precision: 0.95\n",
      "Recall: 0.94\n",
      "F1 Score: 0.94\n",
      "Sensibilidad: 1.00\n",
      "Especificidad: 1.00\n"
     ]
    }
   ],
   "source": [
    "#EXERCICI 3: Entrena’ls usant diferents paràmetres que admeten per tal de millorar-ne la predicció.\n",
    "# Separa los datos en características (atributos) y etiquetas (clase)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Separa los datos en conjuntos de entrenamiento y prueba (70% para entrenamiento y 30% para prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normaliza los datos para que todas las características tengan la misma escala\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Entrena el modelo KNN utilizando el conjunto de entrenamiento. En este caso, utilizaremos un valor de k=5. \n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Haz predicciones sobre el conjunto de prueba utilizando el modelo entrenado. \n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evalúa el rendimiento del modelo calculando la precisión (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo KNN: {accuracy:.2f}')\n",
    "\n",
    "# Calcula la matriz de confusión y muestra los resultados\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de confusión:')\n",
    "print(confusion)\n",
    "\n",
    "# Calcula precision, recall y F1 Score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calcula sensibilidad y especificidad a partir de la matriz de confusión\n",
    "sensitivity = confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "specificity = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "\n",
    "# Muestra los resultados de las métricas\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1 Score: {:.2f}\".format(f1))\n",
    "print(\"Sensibilidad: {:.2f}\".format(sensitivity))\n",
    "print(\"Especificidad: {:.2f}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "76f0ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Color intensity', 'Proline'], dtype='object')\n",
      "Precisión del modelo KNN utilizando las dos características seleccionadas: 0.72\n",
      "El proceso utilizado, no mejoró la precisión del modelo\n"
     ]
    }
   ],
   "source": [
    "#Exercici 5\n",
    "#Aplica algun procés d'enginyeria per millorar els resultats (normalització, estandardització, mostreig...)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Aplicar la selección de características\n",
    "best_features = SelectKBest(score_func=chi2, k=2)\n",
    "X_new = best_features.fit_transform(X, y)\n",
    "\n",
    "# Imprimir las características seleccionadas\n",
    "print(X.columns[best_features.get_support()])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separar los datos en conjuntos de entrenamiento y prueba utilizando las características seleccionadas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenar el modelo KNN utilizando las dos características seleccionadas\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones sobre el conjunto de prueba utilizando el modelo entrenado\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo utilizando la precisión (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo KNN utilizando las dos características seleccionadas: {accuracy:.2f}')\n",
    "print(\"El proceso utilizado, no mejoró la precisión del modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a04021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 94.44%\n",
      "Matriz de Confusión:\n",
      " [[18  1  0]\n",
      " [ 0 19  2]\n",
      " [ 0  0 14]]\n",
      "Sensibilidad por clase: [0.9473684210526315, 0.9047619047619048, 1.0]\n",
      "Especificidad por clase: [1.0, 0.9696969696969697, 0.95]\n",
      "F1 score:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.95      0.97        19\n",
      "           2       0.95      0.90      0.93        21\n",
      "           3       0.88      1.00      0.93        14\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.94      0.95      0.94        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DESARROLLO:\n",
    "#Exercici 1: Segundo modelo: SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar los datos en características (X) y etiquetas (y)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# crear un clasificador SVM y ajustarlo a los datos de entrenamiento\n",
    "svm_clf = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones sobre los datos de prueba\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy*100))\n",
    "\n",
    "# calcular la matriz de confusión\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "print(\"Matriz de Confusión:\\n\", cm_svm)\n",
    "\n",
    "# calcular la sensibilidad y especificidad\n",
    "if cm_svm.shape[0] == 2:\n",
    "    tn, fp, fn, tp = cm_svm.ravel()\n",
    "    sens = tp / (tp + fn)\n",
    "    espec = tn / (tn + fp)\n",
    "    print(\"Sensibilidad:\", sens)\n",
    "    print(\"Especificidad:\", espec)\n",
    "elif cm_svm.shape[0] > 2:\n",
    "    sens = []\n",
    "    espec = []\n",
    "    for i in range(cm_svm.shape[0]):\n",
    "        tn = np.sum(np.delete(np.delete(cm_svm, i, 0), i, 1))\n",
    "        fp = np.sum(np.delete(cm_svm, i, 0)[:, i])\n",
    "        fn = np.sum(np.delete(cm_svm, i, 1)[i, :])\n",
    "        tp = cm_svm[i, i]\n",
    "        sens.append(tp / (tp + fn))\n",
    "        espec.append(tn / (tn + fp))\n",
    "    print(\"Sensibilidad por clase:\", sens)\n",
    "    print(\"Especificidad por clase:\", espec)\n",
    "else:\n",
    "    print(\"La matriz de confusión no es válida.\")\n",
    "    \n",
    "# calcular el F1 score\n",
    "f1_svm = classification_report(y_test, y_pred_svm)\n",
    "print(\"F1 score:\\n\", f1_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESPUESTA ejercicio 2: Ambos modelos tienen una precisión similar. Sin embargo, el modelo SVC proporciona información adicional como la sensibilidad y la especificidad por clase, así como la precisión, el recall y el F1-score para cada clase individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e75ff194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo SVM: 94.44%\n",
      "El cambio de parámetros no mejoró la precisión del modelo\n"
     ]
    }
   ],
   "source": [
    "#EXERCICI 3 DE MODELO SVC\n",
    "#Entrena’ls usant els diferents paràmetres que admeten per tal de millorar-ne la predicció.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parámetros a evaluar\n",
    "param_grid = {'C': [0.1, 1, 10, 100]}\n",
    "\n",
    "# Clasificador SVM\n",
    "svm_clf = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Realizar la búsqueda de cuadrícula\n",
    "grid_search = GridSearchCV(svm_clf, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y la precisión correspondiente\n",
    "best_svm_clf = grid_search.best_estimator_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = best_svm_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precisión del modelo SVM: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"El cambio de parámetros, no mejoró la precisión del modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc7fa939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision media del modelo KNN: 0.69\n",
      "Precision media del modelo SVM: 0.96\n",
      "En este caso, la precisión media del modelo KNN es 0.69, lo que significa que, en promedio, el modelo KNN acertó en un 69% de las predicciones realizadas. Por otro lado, la precisión media del modelo SVM es 0.96, lo que indica que, en promedio, el modelo SVM tuvo una tasa de acierto del 96% en sus predicciones.\n"
     ]
    }
   ],
   "source": [
    "#Exercici 4: Compara el seu rendiment fent servir l’aproximació traint/test o cross-validation.\n",
    "    \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Modelo 1 - KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "scores_knn = cross_val_score(knn, X, y, cv=5)\n",
    "print(f\"Precision media del modelo KNN: {scores_knn.mean():.2f}\")\n",
    "\n",
    "# Modelo 2 - SVM\n",
    "svm_clf = SVC(kernel='linear', C=1, random_state=42)\n",
    "scores_svm = cross_val_score(svm_clf, X, y, cv=5)\n",
    "print(f\"Precision media del modelo SVM: {scores_svm.mean():.2f}\")\n",
    "print(\"En este caso, la precisión media del modelo KNN es 0.69, lo que significa que, en promedio, el modelo KNN acertó en un 69% de las predicciones realizadas. Por otro lado, la precisión media del modelo SVM es 0.96, lo que indica que, en promedio, el modelo SVM tuvo una tasa de acierto del 96% en sus predicciones.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a3584c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 94.44%\n",
      "El método de normalización con MinMaxScaler, no mejoró la precisión del modelo\n"
     ]
    }
   ],
   "source": [
    "#Exercici 5-MODELO 2\n",
    "#Aplica algun procés d'enginyeria per millorar els resultats (normalització, estandardització, mostreig...)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Separar los datos en características (X) y etiquetas (y)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalizar los datos con MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# crear un clasificador SVM y ajustarlo a los datos de entrenamiento normalizados\n",
    "svm_clf = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones sobre los datos de prueba normalizados\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print('Precisión del modelo: {:.2f}%'.format(accuracy*100))\n",
    "print(\"El método de normalización con MinMaxScaler, no mejoró la precisión del modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18884d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
