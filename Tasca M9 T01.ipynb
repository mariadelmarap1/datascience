{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1353214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/usuario/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/usuario/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/usuario/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/usuario/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6c7def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 14), ('.', 13), ('stars', 9), ('are', 7), (',', 6), ('you', 5), ('of', 5), ('they', 4), ('For', 4), ('all', 4), ('one', 4), ('at', 4), ('will', 4), ('be', 4), ('have', 3), ('in', 3), ('And', 3), ('I', 3), ('shall', 3), ('not', 2), ('for', 2), ('who', 2), ('others', 2), ('no', 2), ('sky', 2), ('were', 2), ('as', 2), ('”', 2), ('“', 2), ('night', 2), ('look', 2), ('In', 2), ('laughing', 2), ('so', 2), ('love', 2), ('stars…', 2), ('All', 1), ('men', 1), ('but', 1), ('same', 1), ('things', 1), ('different', 1), ('people', 1), ('some', 1), ('travelers', 1), ('guides', 1), ('more', 1), ('than', 1), ('little', 1), ('lights', 1), ('scholars', 1), ('problems', 1), ('businessman', 1), ('wealth', 1), ('But', 1), ('these', 1), ('silent', 1), ('You–you', 1), ('alone–will', 1), ('else', 1), ('has', 1), ('them–', 1), ('up', 1), ('My', 1), ('star', 1), ('just', 1), ('living', 1), ('them', 1), ('it', 1), ('if', 1), ('when', 1), ('to', 1), ('watch', 1), ('You–only', 1), ('you–will', 1), ('that', 1), ('can', 1), ('laugh', 1), ('leave', 1), ('There', 1), ('is', 1), ('sweetness', 1), ('laughter', 1), ('and', 1), ('memories', 1), ('those', 1), ('we', 1)]\n"
     ]
    }
   ],
   "source": [
    "# text to analyze\n",
    "text = \"\"\"All men have the stars but they are not the same things for different people. For some, who are travelers, the stars are guides. For others they are no more than little lights in the sky. For others, who are scholars, they are problems. For businessman they were wealth. But all these stars are silent.\n",
    "You–you alone–will have the stars as no one else has them–”\n",
    "“And at night you will look up at the stars.\n",
    "My star will just be one of the stars, for you. “In one of the stars I shall be living. In one of them I shall be laughing. And so it will be as if all the stars were laughing, when you look at the sky at night\n",
    "And so you will love to watch all the stars…\n",
    "You–only you–will have stars that can laugh.\n",
    "I shall not leave you”\n",
    "There is sweetness\n",
    "in the laughter of all the stars….\n",
    "and in the memories of those we love.\"\"\"\n",
    "\n",
    "# tokenize the text into words\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# create a frequency distribution of the words\n",
    "freq_dist = FreqDist(words)\n",
    "\n",
    "# print the frequency distribution\n",
    "print(freq_dist.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f67581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['men', 'talk', 'star', 'differ', 'one', 'anoth', 'star', 'guid', 'travel', 'men', 'look', 'star', 'find', 'silent', 'countless', 'star', 'perhap', 'three', 'four', 'mean', 'rest', 'littl', 'light', 'sky', 'yet', 'yet', 'love', 'gaze', 'star', 'often', 'think', 'night', 'aliv', 'richli', 'color', 'day']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Descargar stopwords y crear objeto stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Texto de ejemplo\n",
    "texto = \"Men talk of stars and differ from one another in star-guided travel. Other men look up at the stars and find them silent. Of all the countless stars, perhaps only three or four have a meaning for me. As for the rest, they are just little lights in the sky. And yet...and yet, I love to gaze up at the stars... I often think that night is more alive and more richly colored than the day... \"\n",
    " \n",
    "# Aplicar expresión regular para filtrar signos de puntuación\n",
    "palabras = re.findall(r'\\b\\w+\\b', texto)\n",
    " \n",
    "# Filtrar stopwords\n",
    "palabras_filtradas = [palabra for palabra in palabras if palabra.lower() not in stop_words]\n",
    "\n",
    "# Aplicar stemming\n",
    "palabras_stem = [stemmer.stem(palabra) for palabra in palabras_filtradas]\n",
    "\n",
    "print(palabras_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3648e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimiento general del texto: 0.22711666666666666\n",
      "Sentimiento general del texto es negativo ya que está más cercano a -1\n"
     ]
    }
   ],
   "source": [
    "#from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Crear objeto del analizador de sentimiento\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analizar cada oración del texto\n",
    "sentimientos = []\n",
    "for oracion in nltk.sent_tokenize(texto):\n",
    "    sentimiento = sia.polarity_scores(oracion)['compound']\n",
    "    sentimientos.append(sentimiento)\n",
    "\n",
    "# Calcular sentimiento general del texto\n",
    "sentimiento_general = sum(sentimientos) / len(sentimientos)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Sentimiento general del texto:\", sentimiento_general)\n",
    "\n",
    "#Interpretación: El resultado será un número entre -1 y 1 que indica el sentimiento general del texto, donde valores cercanos a -1 indican sentimiento negativo, valores cercanos a 1 indican sentimiento positivo y valores cercanos a 0 indican sentimiento neutro.\n",
    "# Imprimir interpretación\n",
    "print(\"Sentimiento general del texto es negativo ya que está más cercano a -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b2a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
